import { HeroPattern } from '@/components/HeroPattern'

export const metadata = {
	title: 'Clips AI | AI Video Repurposing for Developers',
	description: 'Clips AI is a python library that allows developers to automatically convert long videos into clips.',
}



<HeroPattern />

# Clips AI Documentation

Clips AI is an open-source Python library that automatically converts long videos into
clips. With just a few lines of code, you can segment a video into multiple clips and
resize its aspect ratio from 16:9 to 9:16. {{ className: 'lead' }}

<div className="not-prose mb-16 mt-6 flex gap-3">
	<Button href="https://github.com/ClipsAI/clipsai" target="_blank" arrow="right">
    	<>GitHub</>
  	</Button>
  	{/* <Button href="https://demo.clipsai.com/projects" target="_blank" variant="outline">
    	<>Demo</>
  	</Button> */}
</div>



# Quickstart

<Note>
    Clips AI is designed for audio-centric, narrative-based videos such as podcasts,
    interviews, speeches, and sermons. It actively employs video transcripts to identify
    and create clips. Our resizing algorithm dynamically reframes and focuses on the
    current speaker, converting the video into various aspect ratios.
</Note>

## Installation

```bash {{ language: 'python' }}
pip install clipsai
```

```bash {{ language: 'python' }}
pip install whisperx@git+https://github.com/m-bain/whisperx.git
```



## Creating clips

Clips are created based on the transcript of a video. You'll first need to transcribe
the video, and then you can create clips based on the transcript.
[WhisperX](https://github.com/m-bain/whisperX) is utilized under the hood to transcribe
videos.

```python
from clipsai import clip, transcribe

transcripiton = transcribe("video.mp4")
clips = clip(transcripiton)

print("StartTime: ", clips[0].start_time)
print("EndTime: ", clips[0].end_time)
```

<div className="not-prose">
	<Button href="/references/clip" variant="text" arrow="right">
    	<>Read clipping reference</>
  	</Button>
</div>

## Resizing a video

You'll need to create an access token on hugging face to resize a video because 
[Pyannote](https://github.com/pyannote/pyannote-audio) is utilized for speaker 
diarization. You won't be charged for using Pyannote and instructions are on the
[Pyannote HuggingFace ](https://huggingface.co/pyannote/speaker-diarization-3.0) page.


```python
from clipsai import resize

crops = resize(
    video_file_path="video.mp4",
    pyannote_auth_token="pyannote_token",
    aspect_ratio=(9, 16)
)

print("Crops: ", crops.segments)
```


<div className="not-prose">
	<Button href="/references/resize" variant="text" arrow="right">
    	<>Read resizing reference</>
  	</Button>
</div>
