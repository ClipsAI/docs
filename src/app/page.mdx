import { HeroPattern } from '@/components/HeroPattern'

export const metadata = {
	title: 'Clips AI | AI Video Repurposing for Developers',
	description: 'Clips AI is a python library that allows developers to automatically convert long videos into clips.',
}



<HeroPattern />

# Clips AI Documentation

Clips AI is an open-source Python library that automatically converts longform video into clips. With just a few lines of code, you can segment a video into multiple clips and resize its aspect ratio from 16:9 to 9:16. {{ className: 'lead' }}

<div className="not-prose mb-16 mt-6 flex gap-3">
	<Button href="https://github.com/ClipsAI/clipsai" target="_blank" arrow="right">
    	<>GitHub</>
  	</Button>
    <Button href="https://demo.clipsai.com" target="_blank" variant="outline">
    	<>Demo</>
  	</Button>
</div>



# Quickstart

<Note>
    Clips AI is designed for audio-centric, narrative-based videos such as podcasts, interviews, speeches, and sermons. Our clipping algorithm analyzes a video's transcript to identify and create clips. Our resizing algorithm dynamically reframes videos to focuse on the current speaker, converting the video into various aspect ratios.
</Note>

## Installation

```bash {{ language: 'python' }}
pip install clipsai
```

```bash {{ language: 'python' }}
pip install whisperx@git+https://github.com/m-bain/whisperx.git
```



## Creating clips

Since clips are found using the video's transcript, the video must first be transcribed. Transcribing is done with [WhisperX](https://github.com/m-bain/whisperX), an open-source wrapper on [Whisper](https://github.com/openai/whisper) with additional functionality for detecting start and stop times for each word. For trimming the original video into a chosen clip, refer to the clipping reference.

```python
from clipsai import ClipFinder, Transcriber

transcriber = Transcriber()
transcription = transcriber.transcribe(audio_file_path="/abs/path/to/video.mp4")

clipfinder = ClipFinder()
clips = clipfinder.find_clips(transcription=transcription)

print("StartTime: ", clips[0].start_time)
print("EndTime: ", clips[0].end_time)
```

<div className="not-prose">
	<Button href="/references/clip" variant="text" arrow="right">
    	<>Read clipping reference</>
  	</Button>
</div>

## Resizing a video

A hugging face access token is required to resize a video since [Pyannote](https://github.com/pyannote/pyannote-audio) is utilized for speaker diarization. You won't be charged for using Pyannote and instructions are on the [Pyannote HuggingFace ](https://huggingface.co/pyannote/speaker-diarization-3.0#requirements) page. For resizing the original video to the desired aspect ratio, refer to the resizing reference.


```python
from clipsai import resize

crops = resize(
    video_file_path="/abs/path/to/video.mp4",
    pyannote_auth_token="pyannote_token",
    aspect_ratio=(9, 16)
)

print("Crops: ", crops.segments)
```


<div className="not-prose">
	<Button href="/references/resize" variant="text" arrow="right">
    	<>Read resizing reference</>
  	</Button>
</div>
