export const metadata = {
  title: 'Resize',
  description:
    'On this page, weâ€™ll dive into the different conversation endpoints you can use to manage conversations programmatically.',
}

# Resize

Clips AI's resizing feature utilizes
[Pyannote](https://huggingface.co/pyannote/speaker-diarization-3.0) for speaker
diarization and segmenting videos based on different speakers. Scene changes are
detected using [PySceneDetect](https://www.scenedetect.com/docs/0.6.2/), which
identifies transitions within the video. For face detection and landmark identification
to focus on speakers' faces, the library utilizes
[MTCNN](https://github.com/timesler/facenet-pytorch) and
[MediaPipe](https://github.com/google/mediapipe). A K-Means algorithm clusters similar
bounding boxes, ensuring consistent speaker focus across frames. This process
dynamically reframes and resizes videos, optimizing for various aspect ratios while
maintaining speaker-centric visual focus. For a detailed explanation, read
[here](https://drive.google.com/file/d/13Oj38gIW8U6OfALtQR5AIDMQ9ZaLw_4O/view?usp=sharing).{{ className: 'lead' }}

## Crops Class

Represents the crop and resize information of a video, including original dimensions,
crop dimensions, and segments of the video that were cropped. Segments provide the x and
y position of the video to start and crop from, as well as the speakers present in the
segment, and the start and end time of the segment.

### Properties

<Properties>
    <Property name="crop_width" type="int">
        The width of the resized video based on the number of pixels.
    </Property>
    <Property name="crop_height" type="int">
        The height of the resized video based on the number of pixels.
    </Property>
    <Property name="original_width" type="int">
        The width of the original video based on the number of pixels.
    </Property>
    <Property name="original_height" type="int">
        The height of the original video based on the number of pixels.
    </Property>
    <Property name="segments" type="List[Segment]">
        The list of Segments providing the crop coordinates and times.
    </Property>
</Properties>

### Methods

<Properties>
    <Property name="add_segment(segment: Segment)" type="None">
        Add a new segment to the crops.
    </Property>
    <Property name="remove_segment(index: int)" type="Segment">
        Remove a segment from the crops by index.
    </Property>
    <Property name="to_dict()" type="dict">
        Returns a dictionary representation of the Crops instance.
    </Property>
</Properties>

---

## Segment Class

Represents a segment of a video that was cropped, including the speakers, start and end
times, and the crop coordinates.

### Properties

<Properties>
    <Property name="x" type="int">
        The x coordinate of the top left corner of the crop from the original video.
    </Property>
    <Property name="y" type="int">
        The y coordinate of the top left corner of the crop from the original video.
    </Property>
    <Property name="start_time" type="float">
        The start time of the segment in seconds.
    </Property>
    <Property name="end_time" type="float">
        The end time of the segment in seconds.
    </Property>
    <Property name="speakers" type="List[int]">
        Returns a list of speaker identifiers in this segment. Each identifier 
        uniquely represents a speaker in the entire video.
    </Property>
</Properties>

### Methods

<Properties>
    <Property name="update_coordinates(x: int, y: int)" type="None">
        Update the crop coordinates of the segment.
    </Property>
    <Property name="to_dict()" type="dict">
        Returns a dictionary representation of the Segment properties.
    </Property>
</Properties>


---

## Resize Function

<Row>
  <Col>

    Resizes a video to a specified aspect ratio, with default being 9:16. It involves 
    speaker diarization, scene detection, and face detection for resizing.

    ### Required parameters

    <Properties>
        <Property name="video_file_path" type="string">
            Absolute path to the video file.
        </Property>
        <Property name="pyannote_auth_token" type="string">
            Authentication token for Pyannote, obtained from HuggingFace.
        </Property>
        <Property name="aspect_ratio" type="tuple[int, int]">
            The target aspect ratio for resizing the video (width, height).
        </Property>
    </Properties>

    ### Optional parameters

    <Properties>
        <Property name="min_segment_duration" type="float">
            The minimum duration in seconds for a diarized speaker segment to be considered. Default is 1.5.
        </Property>
        <Property name="samples_per_segment" type="int">
            The number of samples to take per speaker segment for face detection. Default is 13.
        </Property>
        <Property name="face_detect_width" type="int">
            The width in pixels to which the video will be downscaled for face detection. Default is 960.
        </Property>
        <Property name="face_detect_margin" type="int">
            Margin around detected faces, used in the MTCNN face detector. Default is 20.
        </Property>
        <Property name="face_detect_post_process" type="bool">
            If set to True, post-processing is applied to the face detection output to make it appear more natural. Default is False.
        </Property>
        <Property name="n_face_detect_batches" type="int">
            Number of batches for processing face detection when using GPUs. Default is 8.
        </Property>
        <Property name="min_scene_duration" type="float">
            Minimum duration in seconds for a scene to be considered during scene detection. Default is 0.25.
        </Property>
        <Property name="scene_merge_threshold" type="float">
            Threshold in seconds for merging scene changes with speaker segments. Default is 0.25.
        </Property>
        <Property name="time_precision" type="int">
            Precision (number of decimal places) for start and end times in diarization. Default is 6.
        </Property>
        <Property name="device" type="string">
            The compute device ('auto', 'cpu', or 'cuda') for processing. Default is 'auto'.
        </Property>
    </Properties>

  </Col>

  <Col sticky>

    ```python {{ title: 'Request' }}
    from clipsai import resize

    crops = resize(
        video_file_path="video.mp4",
        pyannote_auth_token="pyannote_token",
        aspect_ratio=(9, 16)
    )
    ```


    ```json {{ title: 'Response' }}
    {
      "id": "xgQQXg3hrtjh7AvZ",
      "contact_id": "WAz8eIbvDR60rouK",
      "group_id": null,
      "pinned_message_id": null,
      "is_pinned": false,
      "is_muted": false,
      "last_active_at": null,
      "last_opened_at": null,
      "created_at": 692233200,
      "archived_at": null
    }
    ```

  </Col>
</Row>
